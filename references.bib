@article{deruytervansteveninckEndtoendOptimizationProsthetic2022,
  title = {End-to-End Optimization of Prosthetic Vision},
  author = {family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and Güçlü, Umut and family=Wezel, given=Richard, prefix=van, useprefix=true and family=Gerven, given=Marcel, prefix=van, useprefix=true},
  date = {2022-02-28},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {22},
  number = {2},
  pages = {20},
  issn = {1534-7362},
  doi = {10.1167/jov.22.2.20},
  url = {https://doi.org/10.1167/jov.22.2.20},
  urldate = {2024-05-10},
  abstract = {Neural prosthetics may provide a promising solution to restore visual perception in some forms of blindness. The restored prosthetic percept is rudimentary compared to normal vision and can be optimized with a variety of image preprocessing techniques to maximize relevant information transfer. Extracting the most useful features from a visual scene is a nontrivial task and optimal preprocessing choices strongly depend on the context. Despite rapid advancements in deep learning, research currently faces a difficult challenge in finding a general and automated preprocessing strategy that can be tailored to specific tasks or user requirements. In this paper, we present a novel deep learning approach that explicitly addresses this issue by optimizing the entire process of phosphene generation in an end-to-end fashion. The proposed model is based on a deep auto-encoder architecture and includes a highly adjustable simulation module of prosthetic vision. In computational validation experiments, we show that such an approach is able to automatically find a task-specific stimulation protocol. The results of these proof-of-principle experiments illustrate the potential of end-to-end optimization for prosthetic vision. The presented approach is highly modular and our approach could be extended to automated dynamic optimization of prosthetic vision for everyday tasks, given any specific constraints, accommodating individual requirements of the end-user.},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\D2H6LCK2\\de Ruyter van Steveninck e.a. - 2022 - End-to-end optimization of prosthetic vision.pdf;C\:\\Users\\marc_\\Zotero\\storage\\859NWS4K\\article.html}
}

@article{deruytervansteveninckRealworldIndoorMobility2022,
  title = {Real-World Indoor Mobility with Simulated Prosthetic Vision: {{The}} Benefits and Feasibility of Contour-Based Scene Simplification at Different Phosphene Resolutions},
  shorttitle = {Real-World Indoor Mobility with Simulated Prosthetic Vision},
  author = {family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and family=Gestel, given=Tom, prefix=van, useprefix=true and Koenders, Paula and family=Ham, given=Guus, prefix=van der, useprefix=true and Vereecken, Floris and Güçlü, Umut and family=Gerven, given=Marcel, prefix=van, useprefix=true and Güçlütürk, Yağmur and family=Wezel, given=Richard, prefix=van, useprefix=true},
  date = {2022-02-01},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {22},
  number = {2},
  pages = {1},
  issn = {1534-7362},
  doi = {10.1167/jov.22.2.1},
  url = {https://doi.org/10.1167/jov.22.2.1},
  urldate = {2024-05-11},
  abstract = {Neuroprosthetic implants are a promising technology for restoring some form of vision in people with visual impairments via electrical neurostimulation in the visual pathway. Although an artificially generated prosthetic percept is relatively limited compared with normal vision, it may provide some elementary perception of the surroundings, re-enabling daily living functionality. For mobility in particular, various studies have investigated the benefits of visual neuroprosthetics in a simulated prosthetic vision paradigm with varying outcomes. The previous literature suggests that scene simplification via image processing, and particularly contour extraction, may potentially improve the mobility performance in a virtual environment. In the current simulation study with sighted participants, we explore both the theoretically attainable benefits of strict scene simplification in an indoor environment by controlling the environmental complexity, as well as the practically achieved improvement with a deep learning-based surface boundary detection implementation compared with traditional edge detection. A simulated electrode resolution of 26 × 26 was found to provide sufficient information for mobility in a simple environment. Our results suggest that, for a lower number of implanted electrodes, the removal of background textures and within-surface gradients may be beneficial in theory. However, the deep learning-based implementation for surface boundary detection did not improve mobility performance in the current study. Furthermore, our findings indicate that, for a greater number of electrodes, the removal of within-surface gradients and background textures may deteriorate, rather than improve, mobility. Therefore, finding a balanced amount of scene simplification requires a careful tradeoff between informativity and interpretability that may depend on the number of implanted electrodes.},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\FZYDCCTU\\de Ruyter van Steveninck e.a. - 2022 - Real-world indoor mobility with simulated prosthet.pdf;C\:\\Users\\marc_\\Zotero\\storage\\J7IKJKKU\\article.html}
}

@article{liuNarrativeReviewCortical2022,
  title = {A Narrative Review of Cortical Visual Prosthesis Systems: The Latest Progress and Significance of Nanotechnology for the Future},
  shorttitle = {A Narrative Review of Cortical Visual Prosthesis Systems},
  author = {Liu, Xi and Chen, Peipei and Ding, Xuemeng and Liu, Anning and Li, Peng and Sun, Cheng and Guan, Huaijin},
  date = {2022-06},
  journaltitle = {Annals of Translational Medicine},
  shortjournal = {Ann Transl Med},
  volume = {10},
  number = {12},
  eprint = {35845476},
  eprinttype = {pmid},
  pages = {716},
  issn = {2305-5839},
  doi = {10.21037/atm-22-2858},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9279795/},
  urldate = {2024-06-12},
  abstract = {Background and Objective We sought to review the latest developments in cortical visual prosthesis (CVP) systems and the significance of nanotechnology for the future. Over the past century, CVP systems have been researched and developed, resulting in various unique surgical and mechanical techniques. Research findings indicate that partial vision recovery is possible, with improvements in coarse target functions and performance in routine activities. Methods This review discusses the architecture and physiology of the visual cortex, the neuroplasticity of the blind brain, and the history of CVP development, and also provides an update on the CVP systems currently being examined in research and clinical trials. Due to advances in nanotechnology, it is possible to make CVPs that are smaller, more efficient, and more biocompatible than ever before. Key Content and Findings Currently, 3 CVPs have entered clinical trials, and several additional systems are undergoing preclinical reviews to determine the safety of the devices for chronic implantation. This development provides the first indication that the area of cortical vision restoration medication may be able to meaningfully benefit blind people. However, several significant technical and biological challenges need to be solved before the gap between artificial and natural eyesight can be reconciled. Rapid breakthroughs in nanotechnology have considerably increased its use in biological domains. Conclusions This paper summarizes the recent progress of CVP in recent years and its future development direction. It is forecasted that nanotechnology can provide better technical support for the development of CVP.},
  pmcid = {PMC9279795},
  file = {C:\Users\marc_\Zotero\storage\X3FCEP5X\Liu e.a. - 2022 - A narrative review of cortical visual prosthesis s.pdf}
}

@article{vandergrintenBiologicallyPlausiblePhosphene2024,
  title = {Towards Biologically Plausible Phosphene Simulation for the Differentiable Optimization of Visual Cortical Prostheses},
  author = {family=Grinten, given=Maureen, prefix=van der, useprefix=true and family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and Lozano, Antonio and Pijnacker, Laura and Rueckauer, Bodo and Roelfsema, Pieter and family=Gerven, given=Marcel, prefix=van, useprefix=true and family=Wezel, given=Richard, prefix=van, useprefix=true and Güçlü, Umut and Güçlütürk, Yağmur},
  editor = {Baker, Chris I and Barry, Michael P},
  date = {2024-02-22},
  journaltitle = {eLife},
  volume = {13},
  pages = {e85812},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.85812},
  url = {https://doi.org/10.7554/eLife.85812},
  urldate = {2024-05-14},
  abstract = {Blindness affects millions of people around the world. A promising solution to restoring a form of vision for some individuals are cortical visual prostheses, which bypass part of the impaired visual pathway by converting camera input to electrical stimulation of the visual system. The artificially induced visual percept (a pattern of localized light flashes, or ‘phosphenes’) has limited resolution, and a great portion of the field’s research is devoted to optimizing the efficacy, efficiency, and practical usefulness of the encoding of visual information. A commonly exploited method is non-invasive functional evaluation in sighted subjects or with computational models by using simulated prosthetic vision (SPV) pipelines. An important challenge in this approach is to balance enhanced perceptual realism, biologically plausibility, and real-time performance in the simulation of cortical prosthetic vision. We present a biologically plausible, PyTorch-based phosphene simulator that can run in real-time and uses differentiable operations to allow for gradient-based computational optimization of phosphene encoding models. The simulator integrates a wide range of clinical results with neurophysiological evidence in humans and non-human primates. The pipeline includes a model of the retinotopic organization and cortical magnification of the visual cortex. Moreover, the quantitative effects of stimulation parameters and temporal dynamics on phosphene characteristics are incorporated. Our results demonstrate the simulator’s suitability for both computational applications such as end-to-end deep learning-based prosthetic vision optimization as well as behavioral experiments. The modular and open-source software provides a flexible simulation framework for computational, clinical, and behavioral neuroscientists working on visual neuroprosthetics.},
  keywords = {bionic vision,blindness,cortical stimulation,deep learning,neural implants,neurotechnology,simulated prosthetic vision},
  file = {C:\Users\marc_\Zotero\storage\KCRLQFNK\van der Grinten e.a. - 2024 - Towards biologically plausible phosphene simulatio.pdf}
}
