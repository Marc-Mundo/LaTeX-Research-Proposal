@article{avrahamRetinalProstheticVision2021,
  title = {Retinal Prosthetic Vision Simulation: Temporal Aspects},
  shorttitle = {Retinal Prosthetic Vision Simulation},
  author = {Avraham, David and Jung, Jae-Hyun and Yitzhaky, Yitzhak and Peli, Eli},
  date = {2021-08},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {18},
  number = {4},
  pages = {0460d9},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/ac1b6c},
  url = {https://dx.doi.org/10.1088/1741-2552/ac1b6c},
  urldate = {2024-06-20},
  abstract = {Objective. The perception of individuals fitted with retinal prostheses is not fully understood, although several retinal implants have been tested and commercialized. Realistic simulations of perception with retinal implants would be useful for future development and evaluation of such systems. Approach. We implemented a retinal prosthetic vision simulation, including temporal features, which have not been previously simulated. In particular, the simulation included temporal aspects such as persistence and perceptual fading of phosphenes and the electrode activation rate. Main results. The simulated phosphene persistence showed an effective reduction in flickering at low electrode activation rates. Although persistence has a positive effect on static scenes, it smears dynamic scenes. Perceptual fading following continuous stimulation affects prosthetic vision of both static and dynamic scenes by making them disappear completely or partially. However, we showed that perceptual fading of a static stimulus might be countered by head-scanning motions, which together with the persistence revealed the contours of the faded object. We also showed that changing the image polarity may improve simulated prosthetic vision in the presence of persistence and perceptual fading. Significance. Temporal aspects have important roles in prosthetic vision, as illustrated by the simulations. Considering these aspects may improve the future design, the training with, and evaluation of retinal prostheses.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\BW9Z4NYT\Avraham e.a. - 2021 - Retinal prosthetic vision simulation temporal asp.pdf}
}

@article{beauchampDynamicStimulationVisual2020,
  title = {Dynamic {{Stimulation}} of {{Visual Cortex Produces Form Vision}} in {{Sighted}} and {{Blind Humans}}},
  author = {Beauchamp, Michael S. and Oswalt, Denise and Sun, Ping and Foster, Brett L. and Magnotti, John F. and Niketeghad, Soroush and Pouratian, Nader and Bosking, William H. and Yoshor, Daniel},
  date = {2020-05},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {181},
  number = {4},
  pages = {774-783.e5},
  issn = {00928674},
  doi = {10.1016/j.cell.2020.04.033},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867420304967},
  urldate = {2024-06-20},
  abstract = {A visual cortical prosthesis (VCP) has long been proposed as a strategy for restoring useful vision to the blind, under the assumption that visual percepts of small spots of light produced with electrical stimulation of visual cortex (phosphenes) will combine into coherent percepts of visual forms, like pixels on a video screen. We tested an alternative strategy in which shapes were traced on the surface of visual cortex by stimulating electrodes in dynamic sequence. In both sighted and blind participants, dynamic stimulation enabled accurate recognition of letter shapes predicted by the brain’s spatial map of the visual world. Forms were presented and recognized rapidly by blind participants, up to 86 forms per minute. These findings demonstrate that a brain prosthetic can produce coherent percepts of visual forms.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\C5S3XMLI\Beauchamp e.a. - 2020 - Dynamic Stimulation of Visual Cortex Produces Form.pdf}
}

@article{bourneTrendsPrevalenceBlindness2021,
  title = {Trends in Prevalence of Blindness and Distance and near Vision Impairment over 30 Years: An Analysis for the {{Global Burden}} of {{Disease Study}}},
  shorttitle = {Trends in Prevalence of Blindness and Distance and near Vision Impairment over 30 Years},
  author = {Bourne, Rupert and Steinmetz, Jaimie D. and Flaxman, Seth and Briant, Paul Svitil and Taylor, Hugh R. and Resnikoff, Serge and Casson, Robert James and Abdoli, Amir and Abu-Gharbieh, Eman and Afshin, Ashkan and Ahmadieh, Hamid and Akalu, Yonas and Alamneh, Alehegn Aderaw and Alemayehu, Wondu and Alfaar, Ahmed Samir and Alipour, Vahid and Anbesu, Etsay Woldu and Androudi, Sofia and Arabloo, Jalal and Arditi, Aries and Asaad, Malke and Bagli, Eleni and Baig, Atif Amin and Bärnighausen, Till Winfried and Parodi, Maurizio Battaglia and Bhagavathula, Akshaya Srikanth and Bhardwaj, Nikha and Bhardwaj, Pankaj and Bhattacharyya, Krittika and Bijani, Ali and Bikbov, Mukharram and Bottone, Michele and Braithwaite, Tasanee and Bron, Alain M. and Butt, Zahid A. and Cheng, Ching-Yu and Chu, Dinh-Toi and Cicinelli, Maria Vittoria and Coelho, João M. and Dagnew, Baye and Dai, Xiaochen and Dana, Reza and Dandona, Lalit and Dandona, Rakhi and Monte, Monte A. Del and Deva, Jenny P. and Diaz, Daniel and Djalalinia, Shirin and Dreer, Laura E. and Ehrlich, Joshua R. and Ellwein, Leon B. and Emamian, Mohammad Hassan and Fernandes, Arthur G. and Fischer, Florian and Friedman, David S. and Furtado, João M. and Gaidhane, Abhay Motiramji and Gaidhane, Shilpa and Gazzard, Gus and Gebremichael, Berhe and George, Ronnie and Ghashghaee, Ahmad and Golechha, Mahaveer and Hamidi, Samer and Hammond, Billy Randall and Hartnett, Mary Elizabeth R. and Hartono, Risky Kusuma and Hay, Simon I. and Heidari, Golnaz and Ho, Hung Chak and Hoang, Chi Linh and Househ, Mowafa and Ibitoye, Segun Emmanuel and Ilic, Irena M. and Ilic, Milena D. and Ingram, April D. and Irvani, Seyed Sina Naghibi and Jha, Ravi Prakash and Kahloun, Rim and Kandel, Himal and Kasa, Ayele Semachew and Kempen, John H. and Keramati, Maryam and Khairallah, Moncef and Khan, Ejaz Ahmad and Khanna, Rohit C. and Khatib, Mahalaqua Nazli and Kim, Judy E. and Kim, Yun Jin and Kisa, Sezer and Kisa, Adnan and Koyanagi, Ai and Kurmi, Om P. and Lansingh, Van Charles and Leasher, Janet L. and Leveziel, Nicolas and Limburg, Hans and Majdan, Marek and Manafi, Navid and Mansouri, Kaweh and McAlinden, Colm and Mohammadi, Seyed Farzad and Mohammadian-Hafshejani, Abdollah and Mohammadpourhodki, Reza and Mokdad, Ali H. and Moosavi, Delaram and Morse, Alan R. and Naderi, Mehdi and Naidoo, Kovin S. and Nangia, Vinay and Nguyen, Cuong Tat and Nguyen, Huong Lan Thi and Ogundimu, Kolawole and Olagunju, Andrew T. and Ostroff, Samuel M. and Panda-Jonas, Songhomitra and Pesudovs, Konrad and Peto, Tunde and Syed, Zahiruddin Quazi and Rahman, Mohammad Hifz Ur and Ramulu, Pradeep Y. and Rawaf, Salman and Rawaf, David Laith and Reinig, Nickolas and Robin, Alan L. and Rossetti, Luca and Safi, Sare and Sahebkar, Amirhossein and Samy, Abdallah M. and Saxena, Deepak and Serle, Janet B. and Shaikh, Masood Ali and Shen, Tueng T. and Shibuya, Kenji and Shin, Jae Il and Silva, Juan Carlos and Silvester, Alexander and Singh, Jasvinder A. and Singhal, Deepika and Sitorus, Rita S. and Skiadaresi, Eirini and Skirbekk, Vegard and Soheili, Amin and Sousa, Raúl A. R. C. and Spurlock, Emma Elizabeth and Stambolian, Dwight and Taddele, Biruk Wogayehu and Tadesse, Eyayou Girma and Tahhan, Nina and Tareque, Md Ismail and Topouzis, Fotis and Tran, Bach Xuan and Travillian, Ravensara S. and Tsilimbaris, Miltiadis K. and Varma, Rohit and Virgili, Gianni and Wang, Ya Xing and Wang, Ningli and West, Sheila K. and Wong, Tien Y. and Zaidi, Zoubida and Zewdie, Kaleab Alemayehu and Jonas, Jost B. and Vos, Theo},
  date = {2021-02-01},
  journaltitle = {The Lancet Global Health},
  shortjournal = {The Lancet Global Health},
  volume = {9},
  number = {2},
  eprint = {33275950},
  eprinttype = {pmid},
  pages = {e130-e143},
  publisher = {Elsevier},
  issn = {2214-109X},
  doi = {10.1016/S2214-109X(20)30425-3},
  url = {https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(20)30425-3/fulltext},
  urldate = {2024-05-29},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\AQF8CS6R\Bourne e.a. - 2021 - Trends in prevalence of blindness and distance and.pdf}
}

@article{deruytervansteveninckEndtoendOptimizationProsthetic2022,
  title = {End-to-End Optimization of Prosthetic Vision},
  author = {family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and Güçlü, Umut and family=Wezel, given=Richard, prefix=van, useprefix=true and family=Gerven, given=Marcel, prefix=van, useprefix=true},
  date = {2022-02-28},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {22},
  number = {2},
  pages = {20},
  issn = {1534-7362},
  doi = {10.1167/jov.22.2.20},
  url = {https://doi.org/10.1167/jov.22.2.20},
  urldate = {2024-05-10},
  abstract = {Neural prosthetics may provide a promising solution to restore visual perception in some forms of blindness. The restored prosthetic percept is rudimentary compared to normal vision and can be optimized with a variety of image preprocessing techniques to maximize relevant information transfer. Extracting the most useful features from a visual scene is a nontrivial task and optimal preprocessing choices strongly depend on the context. Despite rapid advancements in deep learning, research currently faces a difficult challenge in finding a general and automated preprocessing strategy that can be tailored to specific tasks or user requirements. In this paper, we present a novel deep learning approach that explicitly addresses this issue by optimizing the entire process of phosphene generation in an end-to-end fashion. The proposed model is based on a deep auto-encoder architecture and includes a highly adjustable simulation module of prosthetic vision. In computational validation experiments, we show that such an approach is able to automatically find a task-specific stimulation protocol. The results of these proof-of-principle experiments illustrate the potential of end-to-end optimization for prosthetic vision. The presented approach is highly modular and our approach could be extended to automated dynamic optimization of prosthetic vision for everyday tasks, given any specific constraints, accommodating individual requirements of the end-user.},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\D2H6LCK2\\de Ruyter van Steveninck e.a. - 2022 - End-to-end optimization of prosthetic vision.pdf;C\:\\Users\\marc_\\Zotero\\storage\\859NWS4K\\article.html}
}

@article{deruytervansteveninckRealworldIndoorMobility2022,
  title = {Real-World Indoor Mobility with Simulated Prosthetic Vision: {{The}} Benefits and Feasibility of Contour-Based Scene Simplification at Different Phosphene Resolutions},
  shorttitle = {Real-World Indoor Mobility with Simulated Prosthetic Vision},
  author = {family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and family=Gestel, given=Tom, prefix=van, useprefix=true and Koenders, Paula and family=Ham, given=Guus, prefix=van der, useprefix=true and Vereecken, Floris and Güçlü, Umut and family=Gerven, given=Marcel, prefix=van, useprefix=true and Güçlütürk, Yağmur and family=Wezel, given=Richard, prefix=van, useprefix=true},
  date = {2022-02-01},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {22},
  number = {2},
  pages = {1},
  issn = {1534-7362},
  doi = {10.1167/jov.22.2.1},
  url = {https://doi.org/10.1167/jov.22.2.1},
  urldate = {2024-05-11},
  abstract = {Neuroprosthetic implants are a promising technology for restoring some form of vision in people with visual impairments via electrical neurostimulation in the visual pathway. Although an artificially generated prosthetic percept is relatively limited compared with normal vision, it may provide some elementary perception of the surroundings, re-enabling daily living functionality. For mobility in particular, various studies have investigated the benefits of visual neuroprosthetics in a simulated prosthetic vision paradigm with varying outcomes. The previous literature suggests that scene simplification via image processing, and particularly contour extraction, may potentially improve the mobility performance in a virtual environment. In the current simulation study with sighted participants, we explore both the theoretically attainable benefits of strict scene simplification in an indoor environment by controlling the environmental complexity, as well as the practically achieved improvement with a deep learning-based surface boundary detection implementation compared with traditional edge detection. A simulated electrode resolution of 26 × 26 was found to provide sufficient information for mobility in a simple environment. Our results suggest that, for a lower number of implanted electrodes, the removal of background textures and within-surface gradients may be beneficial in theory. However, the deep learning-based implementation for surface boundary detection did not improve mobility performance in the current study. Furthermore, our findings indicate that, for a greater number of electrodes, the removal of within-surface gradients and background textures may deteriorate, rather than improve, mobility. Therefore, finding a balanced amount of scene simplification requires a careful tradeoff between informativity and interpretability that may depend on the number of implanted electrodes.},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\FZYDCCTU\\de Ruyter van Steveninck e.a. - 2022 - Real-world indoor mobility with simulated prosthet.pdf;C\:\\Users\\marc_\\Zotero\\storage\\J7IKJKKU\\article.html}
}

@inproceedings{hanDeepLearningBased2021,
  title = {Deep {{Learning}}–{{Based Scene Simplification}} for {{Bionic Vision}}},
  booktitle = {Augmented {{Humans Conference}} 2021},
  author = {Han, Nicole and Srivastava, Sudhanshu and Xu, Aiwen and Klein, Devi and Beyeler, Michael},
  date = {2021-02-22},
  pages = {45--54},
  publisher = {ACM},
  location = {Rovaniemi Finland},
  doi = {10.1145/3458709.3458982},
  url = {https://dl.acm.org/doi/10.1145/3458709.3458982},
  urldate = {2024-06-21},
  eventtitle = {{{AHs}} '21: {{Augmented Humans International Conference}} 2021},
  isbn = {978-1-4503-8428-5},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\U5AGNM6D\Han e.a. - 2021 - Deep Learning–Based Scene Simplification for Bioni.pdf}
}

@article{hoLongTermResultsEpiretinal2015,
  title = {Long-{{Term Results}} from an {{Epiretinal Prosthesis}} to {{Restore Sight}} to the {{Blind}}},
  author = {Ho, Allen C. and Humayun, Mark S. and Dorn, Jessy D. and Da Cruz, Lyndon and Dagnelie, Gislin and Handa, James and Barale, Pierre-Olivier and Sahel, José-Alain and Stanga, Paulo E. and Hafezi, Farhad and Safran, Avinoam B. and Salzmann, Joel and Santos, Arturo and Birch, David and Spencer, Rand and Cideciyan, Artur V. and De Juan, Eugene and Duncan, Jacque L. and Eliott, Dean and Fawzi, Amani and Olmos De Koo, Lisa C. and Brown, Gary C. and Haller, Julia A. and Regillo, Carl D. and Del Priore, Lucian V. and Arditi, Aries and Geruschat, Duane R. and Greenberg, Robert J.},
  date = {2015-08},
  journaltitle = {Ophthalmology},
  shortjournal = {Ophthalmology},
  volume = {122},
  number = {8},
  pages = {1547--1554},
  issn = {01616420},
  doi = {10.1016/j.ophtha.2015.04.032},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0161642015004157},
  urldate = {2024-06-10},
  abstract = {Purpose: Retinitis pigmentosa (RP) is a group of inherited retinal degenerations leading to blindness due to photoreceptor loss. Retinitis pigmentosa is a rare disease, affecting only approximately 100 000 people in the United States. There is no cure and no approved medical therapy to slow or reverse RP. The purpose of this clinical trial was to evaluate the safety, reliability, and benefit of the Argus II Retinal Prosthesis System (Second Sight Medical Products, Inc, Sylmar, CA) in restoring some visual function to subjects completely blind from RP. We report clinical trial results at 1 and 3 years after implantation. Design: The study is a multicenter, single-arm, prospective clinical trial. Participants: There were 30 subjects in 10 centers in the United States and Europe. Subjects served as their own controls, that is, implanted eye versus fellow eye, and system on versus system off (native residual vision). Methods: The Argus II System was implanted on and in a single eye (typically the worse-seeing eye) of blind subjects. Subjects wore glasses mounted with a small camera and a video processor that converted images into stimulation patterns sent to the electrode array on the retina. Main Outcome Measures: The primary outcome measures were safety (the number, seriousness, and relatedness of adverse events) and visual function, as measured by 3 computer-based, objective tests. Results: A total of 29 of 30 subjects had functioning Argus II Systems implants 3 years after implantation. Eleven subjects experienced a total of 23 serious device- or surgery-related adverse events. All were treated with standard ophthalmic care. As a group, subjects performed significantly better with the system on than off on all visual function tests and functional vision assessments. Conclusions: The 3-year results of the Argus II trial support the long-term safety profile and benefit of the Argus II System for patients blind from RP. Earlier results from this trial were used to gain approval of the Argus II by the Food and Drug Administration and a CE mark in Europe. The Argus II System is the first and only retinal implant to have both approvals. Ophthalmology 2015;122:1547-1554 ª 2015 by the American Academy of Ophthalmology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\LIVA34FP\Ho e.a. - 2015 - Long-Term Results from an Epiretinal Prosthesis to.pdf}
}

@online{houPredictingTemporalDynamics2024,
  title = {Predicting the {{Temporal Dynamics}} of {{Prosthetic Vision}}},
  author = {Hou, Yuchen and Pullela, Laya and Su, Jiaxin and Aluru, Sriya and Sista, Shivani and Lu, Xiankun and Beyeler, Michael},
  date = {2024-05-01},
  eprint = {2404.14591},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.14591},
  url = {http://arxiv.org/abs/2404.14591},
  urldate = {2024-06-20},
  abstract = {Retinal implants are a promising treatment option for degenerative retinal disease. While numerous models have been developed to simulate the appearance of elicited visual percepts ("phosphenes"), these models often either focus solely on spatial characteristics or inadequately capture the complex temporal dynamics observed in clinical trials, which vary heavily across implant technologies, subjects, and stimulus conditions. Here we introduce two computational models designed to accurately predict phosphene fading and persistence under varying stimulus conditions, cross-validated on behavioral data reported by nine users of the Argus II Retinal Prosthesis System. Both models segment the time course of phosphene perception into discrete intervals, decomposing phosphene fading and persistence into either sinusoidal or exponential components. Our spectral model demonstrates state-of-the-art predictions of phosphene intensity over time (r = 0.7 across all participants). Overall, this study lays the groundwork for enhancing prosthetic vision by improving our understanding of phosphene temporal dynamics.},
  pubstate = {preprint},
  keywords = {Computer Science - Computational Engineering Finance and Science},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\EX2SGINT\\Hou e.a. - 2024 - Predicting the Temporal Dynamics of Prosthetic Vis.pdf;C\:\\Users\\marc_\\Zotero\\storage\\TU9YAVX3\\2404.html}
}

@article{liuNarrativeReviewCortical2022,
  title = {A Narrative Review of Cortical Visual Prosthesis Systems: The Latest Progress and Significance of Nanotechnology for the Future},
  shorttitle = {A Narrative Review of Cortical Visual Prosthesis Systems},
  author = {Liu, Xi and Chen, Peipei and Ding, Xuemeng and Liu, Anning and Li, Peng and Sun, Cheng and Guan, Huaijin},
  date = {2022-06},
  journaltitle = {Annals of Translational Medicine},
  shortjournal = {Ann Transl Med},
  volume = {10},
  number = {12},
  eprint = {35845476},
  eprinttype = {pmid},
  pages = {716},
  issn = {2305-5839},
  doi = {10.21037/atm-22-2858},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9279795/},
  urldate = {2024-06-12},
  abstract = {Background and Objective We sought to review the latest developments in cortical visual prosthesis (CVP) systems and the significance of nanotechnology for the future. Over the past century, CVP systems have been researched and developed, resulting in various unique surgical and mechanical techniques. Research findings indicate that partial vision recovery is possible, with improvements in coarse target functions and performance in routine activities. Methods This review discusses the architecture and physiology of the visual cortex, the neuroplasticity of the blind brain, and the history of CVP development, and also provides an update on the CVP systems currently being examined in research and clinical trials. Due to advances in nanotechnology, it is possible to make CVPs that are smaller, more efficient, and more biocompatible than ever before. Key Content and Findings Currently, 3 CVPs have entered clinical trials, and several additional systems are undergoing preclinical reviews to determine the safety of the devices for chronic implantation. This development provides the first indication that the area of cortical vision restoration medication may be able to meaningfully benefit blind people. However, several significant technical and biological challenges need to be solved before the gap between artificial and natural eyesight can be reconciled. Rapid breakthroughs in nanotechnology have considerably increased its use in biological domains. Conclusions This paper summarizes the recent progress of CVP in recent years and its future development direction. It is forecasted that nanotechnology can provide better technical support for the development of CVP.},
  pmcid = {PMC9279795},
  file = {C:\Users\marc_\Zotero\storage\X3FCEP5X\Liu e.a. - 2022 - A narrative review of cortical visual prosthesis s.pdf}
}

@inproceedings{liWearableComputerVision2013,
  title = {Wearable {{Computer Vision Systems}} for a {{Cortical Visual Prosthesis}}},
  booktitle = {2013 {{IEEE International Conference}} on {{Computer Vision Workshops}}},
  author = {Li, Wai Ho},
  date = {2013-12},
  pages = {428--435},
  doi = {10.1109/ICCVW.2013.63},
  url = {https://ieeexplore.ieee.org/document/6755929},
  urldate = {2024-06-21},
  abstract = {Cortical visual prostheses produce bionic vision by translating data from a head worn sensor into spatial-temporal patterns of electrical stimulation of a patient's Primary Visual Cortex (V1). The resulting bionic vision has low resolution, poor dynamic range and other limitations. These limitations are unlikely to change in the next decade due to the combined constraints of technology and biology as well as the slow process of medical device certification. This paper discusses ongoing research on Wearable Computer Vision Systems (WCVS) designed for two purposes: Improving the utility of bionic vision and non-invasive evaluation of visual prosthesis on sighted subjects using Simulated Prosthetic Vision (SPV).},
  eventtitle = {2013 {{IEEE International Conference}} on {{Computer Vision Workshops}}},
  keywords = {Cameras,Electrodes,Implants,MVG,Phosphenes,Retina,Transformative Reality,Visual prosthesis,Visualization,Wearable Computer Vision Systems},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\URCFBX3B\\Li - 2013 - Wearable Computer Vision Systems for a Cortical Vi.pdf;C\:\\Users\\marc_\\Zotero\\storage\\BJ7IFB73\\6755929.html}
}

@article{merabetWhatBlindnessCan2005,
  title = {What Blindness Can Tell Us about Seeing Again: Merging Neuroplasticity and Neuroprostheses},
  shorttitle = {What Blindness Can Tell Us about Seeing Again},
  author = {Merabet, Lotfi B. and Rizzo, Joseph F. and Amedi, Amir and Somers, David C. and Pascual-Leone, Alvaro},
  date = {2005-01},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {6},
  number = {1},
  pages = {71--77},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn1586},
  url = {https://www.nature.com/articles/nrn1586},
  urldate = {2024-05-17},
  abstract = {Significant progress has been made in the development of visual neuroprostheses to restore vision in blind individuals. Appropriate delivery of electrical stimulation to intact visual structures can evoke patterned sensations of light in those who have been blind for many years. However, success in developing functional visual prostheses requires an understanding of how to communicate effectively with the visually deprived brain in order to merge what is perceived visually with what is generated electrically.},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\marc_\Zotero\storage\B5I84TCW\Merabet e.a. - 2005 - What blindness can tell us about seeing again mer.pdf}
}

@article{stevensGlobalPrevalenceVision2013,
  title = {Global {{Prevalence}} of {{Vision Impairment}} and {{Blindness}}},
  author = {Stevens, Gretchen A and White, Richard A and Flaxman, Seth R and Price, Holly and Jonas, Jost B and Keeffe, Jill and Leasher, Janet and Naidoo, Kovin and Pesudovs, Konrad and Resnikoff, Serge and Taylor, Hugh and Bourne, Rupert R A},
  date = {2013},
  volume = {120},
  number = {12},
  abstract = {Purpose: Vision impairment is a leading and largely preventable cause of disability worldwide. However, no study of global and regional trends in the prevalence of vision impairment has been carried out. We estimated the prevalence of vision impairment and its changes worldwide for the past 20 years. Design: Systematic review. Participants: A systematic review of published and unpublished population-based data on vision impairment and blindness from 1980 through 2012. Methods: Hierarchical models were fitted fitted to estimate the prevalence of moderate and severe vision impairment (MSVI; defined as presenting visual acuity {$<$}6/18 but !3/60) and the prevalence of blindness (presenting visual acuity {$<$}3/60) by age, country, and year. Main Outcome Measures: Trends in the prevalence of MSVI and blindness for the period 1990 through 2010. Results: Globally, 32.4 million people (95\% confidence interval [CI], 29.4e36.5 million people; 60\% women) were blind in 2010, and 191 million people (95\% CI, 174e230 million people; 57\% women) had MSVI. The agestandardized prevalence of blindness in older adults (!50 years) was more than 4\% in Western Sub-Saharan Africa (6.0\%; 95\% CI, 4.6\%e7.1\%), Eastern Sub-Saharan Africa (5.7\%; 95\% CI, 4.4\%e6.9\%), South Asia (4.4\%; 95\% CI, 3.5\%e5.1\%), and North Africa and the Middle East (4.6\%; 95\% CI, 3.5\%e5.8\%), in contrast to high-income regions with blindness prevalences of 0.4\% or less. The MSVI prevalence in older adults was highest in South Asia (23.6\%; 95\% CI, 19.4\%e29.4\%), Oceania (18.9\%; 95\% CI, 11.8\%e23.7\%), and Eastern and Western Sub-Saharan Africa and North Africa and the Middle East (95\% CI, 15.9\%e16.8\%). The MSVI prevalence was less than 5\% in all 4 high-income regions. The global age-standardized prevalence of blindness and MSVI for older adults decreased from 3.0\% (95\% CI, 2.7\%e3.4\%) worldwide in 1990 to 1.9\% (95\% CI, 1.7\%e2.2\%) in 2010 and from 14.3\% (95\% CI, 12.1\%e16.2\%) worldwide to 10.4\% (95\% CI, 9.5\%e12.3\%), respectively. When controlling for age, women’s prevalence of blindness was greater than men’s in all world regions. Because the global population has increased and aged between 1990 and 2010, the number of blind has increased by 0.6 million people (95\% CI, À5.2 to 5.3 million people). The number with MSVI may have increased by 19 million people (95\% CI, À8 to 72 million people) from 172 million people (95\% CI, 142e198 million people) in 1990. Conclusions: The age-standardized prevalence of blindness and MSVI has decreased in the past 20 years. However, because of population growth and the relative increase in older adults, the blind population has been stable and the population with MSVI may have increased.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\EJPMQCKC\Stevens e.a. - 2013 - Global Prevalence of Vision Impairment and Blindne.pdf}
}

@article{towleDevelopmentColorVisual2021,
  title = {Toward the Development of a Color Visual Prosthesis},
  author = {Towle, Vernon L. and Pham, Tuan and McCaffrey, Michael and Allen, Danielle and Troyk, Philip R.},
  date = {2021-02},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {18},
  number = {2},
  pages = {023001},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/abd520},
  url = {https://dx.doi.org/10.1088/1741-2552/abd520},
  urldate = {2024-05-11},
  abstract = {Objective. All of the human prosthetic visual systems implanted so far have been achromatic. Schmidt et al (1996 Brain 119 507–22) reported that at low stimulation intensities their subject reported that phosphenes usually had a specific hue, but when the stimulus intensity was increased, they desaturated to white. We speculate here that previous B/W prosthetic systems were unnecessarily over-stimulating the visual cortex to obtain white phosphenes, which may be why unexpected alterations in phosphenes and seizures were not an uncommon occurrence. A color prosthesis would have the advantage of being elicited by lower levels of stimulation, reducing the probability of causing epileptogenic responses. Approach. A ‘hybrid’ mode of stimulation is suggested, involving a combination of B/W and color stimulation, which could provide color information without reducing spatial resolution. Main results. Colors in the real world are spread along intensity and chromatic gradients. Significance. Software implementation strategies are discussed, as are the advantages and challenges for possible color prosthetic systems.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\9FBXMQ3W\Towle e.a. - 2021 - Toward the development of a color visual prosthesi.pdf}
}

@article{vandergrintenBiologicallyPlausiblePhosphene2024,
  title = {Towards Biologically Plausible Phosphene Simulation for the Differentiable Optimization of Visual Cortical Prostheses},
  author = {family=Grinten, given=Maureen, prefix=van der, useprefix=true and family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and Lozano, Antonio and Pijnacker, Laura and Rueckauer, Bodo and Roelfsema, Pieter and family=Gerven, given=Marcel, prefix=van, useprefix=true and family=Wezel, given=Richard, prefix=van, useprefix=true and Güçlü, Umut and Güçlütürk, Yağmur},
  editor = {Baker, Chris I and Barry, Michael P},
  date = {2024-02-22},
  journaltitle = {eLife},
  volume = {13},
  pages = {e85812},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.85812},
  url = {https://doi.org/10.7554/eLife.85812},
  urldate = {2024-05-14},
  abstract = {Blindness affects millions of people around the world. A promising solution to restoring a form of vision for some individuals are cortical visual prostheses, which bypass part of the impaired visual pathway by converting camera input to electrical stimulation of the visual system. The artificially induced visual percept (a pattern of localized light flashes, or ‘phosphenes’) has limited resolution, and a great portion of the field’s research is devoted to optimizing the efficacy, efficiency, and practical usefulness of the encoding of visual information. A commonly exploited method is non-invasive functional evaluation in sighted subjects or with computational models by using simulated prosthetic vision (SPV) pipelines. An important challenge in this approach is to balance enhanced perceptual realism, biologically plausibility, and real-time performance in the simulation of cortical prosthetic vision. We present a biologically plausible, PyTorch-based phosphene simulator that can run in real-time and uses differentiable operations to allow for gradient-based computational optimization of phosphene encoding models. The simulator integrates a wide range of clinical results with neurophysiological evidence in humans and non-human primates. The pipeline includes a model of the retinotopic organization and cortical magnification of the visual cortex. Moreover, the quantitative effects of stimulation parameters and temporal dynamics on phosphene characteristics are incorporated. Our results demonstrate the simulator’s suitability for both computational applications such as end-to-end deep learning-based prosthetic vision optimization as well as behavioral experiments. The modular and open-source software provides a flexible simulation framework for computational, clinical, and behavioral neuroscientists working on visual neuroprosthetics.},
  keywords = {bionic vision,blindness,cortical stimulation,deep learning,neural implants,neurotechnology,simulated prosthetic vision},
  file = {C:\Users\marc_\Zotero\storage\KCRLQFNK\van der Grinten e.a. - 2024 - Towards biologically plausible phosphene simulatio.pdf}
}
